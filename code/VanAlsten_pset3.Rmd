---
title: "PSET 3"
author: "Sarah Van Alsten"
date: "2/4/2020"
output: html_document
---

```{r, message=FALSE, warning=FALSE, echo = FALSE}
#setup
#install.packages("tidyverse")
#install.packages("Hmisc")

#open libraries
library(tidyverse)
library(Hmisc)

```

## Question 1

```{r}

#a.
#function to randomly assign treatment (P = 0.5) given 2 vectors of 
#potential outcomes

treatFx <- function(v1, v0){
  #randomly assign treatment, 1 = treated, 0 = control
  treat <- rbinom(n = length(v1), size = 1, prob = 0.5)
  
  #create vector for obs outcomes under treatment: keep 
  #outcomes if treated, otherwise not observed
  yi1 <- ifelse(treat == 1, v1, NA)
  
  #create vector for obs outcomes under control: keep 
  #outcomes if control, otherwise not observed
  yi0 <- ifelse(treat == 0, v0, NA)
  
  #calculate ATE: mean yi1 - mean yi0
  ate <- mean(yi1, na.rm = T) - mean(yi0, na.rm = T)
  
  #standard error:sqrt(var yi1/n yi1 + var yi0/n yi0)
  se <- sqrt((var(yi1, na.rm = T)/sum(treat == 1)) +
               var(yi0, na.rm = T)/sum(treat == 0))
  
  #t statistic
  tstat <- ate/se

  
  #return p value for t statistic:
  #want two sided, so multiply by 2
  #take abs value and upper tail to keep
  #consistent behavior for treat means gt or lt control means
  return(pt(q = abs(tstat), df = length(v1) - 2, lower.tail = F)*2)
  
}

```

```{r}
#1 and 2
set.seed(02139)

#outcomes under control: mean = 1, var/sd = 1
y0 <- rnorm(n = 1000, mean = 1, sd = 1)

#outcomes under treatment: mean = t = 0.2; var/sd = 1
y1 <- rnorm(n = 1000, mean = 0.2, sd = 1)

#run function
treatFx(y1, y0)


```

The p value for the given set up is ~5.28 * 10^-33, indicating that it is very unlikely that the expected value of observed outcomes in the treatment and control groups are the same. In other words, the average treatment effect is non-zero and statistically significant.


```{r}
#b.
#repeat process 10,000 times
reps.10k.02 <- replicate(n = 10000, 
                         expr = treatFx(v1 = y1, v0 = y0),
                         simplify = "vector")

#get % p values < 0.05
sum(reps.10k.02 < 0.05) / (length(reps.10k.02)) #100% < 0.05

```

100% of calculate p-values in the simulation were less than 0.05. This number gives us the power of our experiment (how often do we correctly reject the null given that the null is true).


```{r, fig.cap="Power Plot", fig.align="center"}
#c.
#function that does repeated simulation, which can be called by map function
#m1 = treatment effect
replicateSimFx <- function(times = 1000, size = 1000, m1){
  
  #generate treatment vector given #obs(size), and mean (m1)
  v1 <- rnorm(n = size, mean = m1, sd = 1)

  #do simulation for 'times' times, with previously generated v0 and our new v1
  res <- replicate(n = times, 
                   expr = treatFx(v0 = y0, v1 = v1), 
                   simplify = "vector")
  
  #return % of values <0.05
  return(sum(res < 0.05) / (length(res)))
  
}


#run simulation for different values of treatment group mean (0 - 1, along increases of .1), 
#1000 reps each per args in replicateSimFx
results <- purrr::map_dbl(seq(0, 1, .1), ~replicateSimFx(m1 = .x))

#plot results
as.data.frame(cbind(results, seq(0, 1, .1))) %>%
  ggplot(aes(x = V2, y = results)) +
  geom_point() +
  geom_line() +
  theme_minimal() +
  labs(x = "Expected Value Yi for Treated", y = "Power") +
  ggtitle("Power for Various Treatment Effect Sizes")


```


We have 100% or approximately 100% power to detect a significant ATE when the expected value of Yi in the treatment group ranges from 0 to 0.7 (as compared to the expected value of 1 in the control group). We still have greater than 80% power to detect a significant ATE when the expected value of Yi in the treatment group is 0.8, but after this power declines rapidly. This tells us that (for a given sample size) we have better ability to detect the 'true' ATE when the difference in outcomes between the treatment and control groups is greater (ie when we have a larger effect size).

Draw one random sample of
50 units from your population without replacement, then repeat the process in part c)
using only that sample. Do the same for sample sizes 100, 200, and 500. Plot lines for
each sample size on the same graph with your result from part c) and clearly label the
different lines. What do you notice? What does this tell you about the relationship
between sample size and your ability to detect treatment effects for a given “true”
ATE? Why might this be the case?

```{r, fig.align = "center", fig.cap="Power For Various Sample Sizes"}
#d.
#add in sampling of diff sizes to previous function: sample.n = sample size, size = popl size
replicateSimFx2 <- function(times = 1000, size = 1000, m1, sample.n){
  
  #generate treatment vector given #obs(size), and mean (m1)
  v1 <- rnorm(n = size, mean = m1, sd = 1)
  
  #generate random sample of size sample.n
  v1.samp <- sample(v1, size = sample.n, replace = FALSE)
 

  #do simulation for 'times' times, with previously generated v0 and our new v1.samp
  res <- replicate(n = times, 
                   expr = treatFx(v0 = y0, v1 = v1.samp), 
                   simplify = "vector")
  
  #return % of values <0.05
  return(sum(res < 0.05) / (length(res)))
  
}


#replicate with sample size 50, various effect sizes 0-1
results.50 <- purrr::map_dbl(seq(0, 1, .1), ~replicateSimFx2(m1 = .x, sample.n = 50))

#draw random sample of 100 and repeat
results.100 <- purrr::map_dbl(seq(0, 1, .1), ~replicateSimFx2(m1 = .x, sample.n = 100))

#draw random sample of 200 and repeat
results.200 <- purrr::map_dbl(seq(0, 1, .1), ~replicateSimFx2(m1 = .x, sample.n = 200))

#draw random sample of 500 and repeat
results.500 <- purrr::map_dbl(seq(0, 1, .1), ~replicateSimFx2(m1 = .x, sample.n = 500))

#add these lines to graph
as.data.frame(cbind(results, 
                    results.50,
                    results.100,
                    results.200,
                    results.500,
                    seq(0, 1, .1))) %>%
  ggplot(aes(x = V6)) +
  #sample size 50
  geom_point(aes(y = results.50, color = "50")) + geom_line(aes(y = results.50, color = "50")) + 
  #sample size 100
  geom_point(aes(y = results.100, color = "100")) + geom_line(aes(y = results.100, color = "100")) +
  #sample size 200
  geom_point(aes(y = results.200, color = "200")) + geom_line(aes(y = results.200, color = "200")) +
  #sample size 500
  geom_point(aes(y = results.500, color = "500")) + geom_line(aes(y = results.500, color = "500")) +
  #sample size 1000
  geom_point(aes(y = results, color = "1000")) + geom_line(aes(y = results, color = "1000")) +
  theme_minimal() +
  labs(x = "Expected Value Yi for Treated", y = "Power") +
  ggtitle("Power for Various Treatment Effect Sizes + Sample Sizes") +
  #add color legend
  scale_color_manual(labels = paste0("n = ", c(100, 1000, 200, 50, 500)),
                     values = c("red", "black", "orange", "blue", "forestgreen"),
                     name = "Sample Size")





```


For a given effect size, power is (generally) greater when the sample size is larger. However, there are diminishing returns to increased sample size. The ability to detect effects of similar magnitude is substantially greater by adding 150 observations (ie going from 50 observations to 200) but you have to add about twice as many to get the same increase in power for subsequent increases in sample size (ie adding 300 observations when going from 200 to 500, or 500 when going from 500 to 1000). Additionally, there is more variablity in curves for smaller samples (they are non-monotonic), indicating how results/estimates drawn from small samples tend to be more variable than results drawn from larger ones.



## Question 2.
```{r}
#reset the seed
set.seed(02139)

#generate vector of cluster memberships
jij <- rep(c(1:50), each = 20)

#draw group level means for each cluster
jij.mu <- runif(n = 50, min = 0, max = 10)

#data frame of cluster num + cluster mean
clusterInfo <- as.data.frame(cbind(c(1:50), jij.mu))

#observation frame to match to clusterInfo
obs.frame <- as.data.frame(cbind(jij)) #1:1000 is individual obs number

#now assign each individual observation its cluster mean
matched <- clusterInfo %>% right_join(obs.frame, by = c("V1" = "jij"))

#add individual error term
jij.error <- rnorm(n = 1000, mean = 0, sd = 1)

#generate thecorrelated error terms as group mean + individual error
group.corr.error <- matched$jij.mu + jij.error

#add to old y0 vector and call y*0
y0star <- y0 + group.corr.error
hist(y0star)


```

To simulate the potential outcomes under control for 1000 clustered individuals (50 groups of 20 units each), I first generated a random group-level mean for each cluster using a random uniform distribution ranging from 0 to 10 and assigned the group mean to every individual within that cluster. I then simulated within cluster variability by adding a random error term to each individual, this time drawn from a normal distribution with a mean of 0 and standard deviation of 1. Finally, to account for sampling variability, I added to each individual an additional error term, drawn from a normal distribution with mean and standard deviation of 1.


```{r}
#b.
#modify function from pt 1 to sample by cluster

treatFxClus <- function(v1, v0, cluster){
  
  #######################################
  # Assign Treatment
  ######################################
  
  #randomly assign treatment by cluster, 1 = treated, 0 = control
  #where 1/2 clusters are treated
  treat <- sample(x = unique(cluster), size = length(unique(cluster))/2, replace = FALSE)
  
  #make a data frame of outcomes and their respective clusters
  df <- as.data.frame(cbind(v1,v0,cluster))
  
  #if cluster was sampled, treated, else control
  df <- df %>%
    mutate(treat = ifelse(cluster %in% treat, 1, 0)) %>%
    #create one observed outcome vec
    mutate(obs = ifelse(treat == 1, v1, v0))
  
  #get cluster group means
  df <- df %>%
    group_by(cluster) %>%
    mutate(groupMean = mean(obs, na.rm = T)) %>%
    ungroup()

  ##########################################
   # Get ATE
   ########################################
   
   #get means of treated/control
  treat.mean <- df %>%
    filter(treat == 1) %>%
    summarise(mean = mean(obs, na.rm = T))
  
  control.mean <- df %>%
    filter(treat == 0) %>%
    summarise(mean = mean(obs, na.rm = T))
  
  #ate:
  ate <- treat.mean$mean - control.mean$mean

  #get variances of treated/control
  treat.var <- df %>%
    filter(treat == 1) %>%
    summarise(var = var(obs, na.rm = T))
  
  control.var <- df %>%
    filter(treat == 0) %>%
    summarise(var = var(obs, na.rm = T))
  
  ##########################################################
  # Get Components of ICC                               
  #########################################################
   
  #global means by treatment
  global.mean.treat <- treat.mean$mean
  global.mean.control <- control.mean$mean
   
  #get btwn sum squares: sum of squared deviations of groupMeans from global mean
  tot.ss.treat <- sum(20*(df[df$treat == 1, "groupMean"] - global.mean.treat)^2)
  tot.ss.cont <- sum(20*(df[df$treat == 0, "groupMean"] - global.mean.control)^2)
  
  cluster.mss <- (tot.ss.treat + tot.ss.cont)/(unique(cluster)-2)
  
  #get within cluster variance 
  between.var <- sum(((df$groupMean - global.mean)^2))
  
  #get ICC
  icc <- between.var/tot.var
  
  #get design effect correction to multiply se to
  design.correction <- 1 + ((20 - 1)*icc)
  
  
  #get p value and perform hypothesis test
  test.res <-
    Hmisc::t.test.cluster(y = df$obs,
                          cluster = df$cluster,
                          group =  df$treat)
  
  
  mod <- lm(obs ~ treat, data = df)
  se <- sqrt(diag(sandwich::vcovCL(mod, cluster = df$cluster)))
  se2 <- sqrt(diag(sandwich::vcovHC(mod, type = "HC1")))
  
  
  #return p value
  return(list(test.res, summary(mod), se, se2, icc, design.correction))

}

```

```{r}
#generate potential outcomes under treatment

#create random treatment effect (mean = tau)
treat.error <- rnorm(n = 1000, mean = 0.2, sd = 1)

y1star <- matched$jij.mu + treat.error

#Run function
treatFxClus(v1 = y1star, v0 = y0star, cluster = matched$V1)


```

Unlike in the original simulation, the test under the clustering structure is not significant.

```{r}
#c. replicate 1000 times for different values of tau 
#create another function that runs results 1000 times each
repCluster1000 <- function(tau, times = 1000){
  
  #create random treatment effect (mean = tau)
  treat.error <- rnorm(n = 1000, mean = 0.2, sd = 1)

  y1star <- matched$jij.mu + treat.error
  
  #do simulation for 1000 times
  res <- replicate(n = times, 
                   expr = treatFxClus(v0 = y0star, v1 = y1star, cluster = matched$V1),
                   simplify = "vector")
  
  #return % of values <0.05
  print(sum(res < 0.05) / (length(res)))
  return(sum(res < 0.05) / (length(res)))
  
}


#run 1000 times at different values of tau
clus.results <- purrr::map_dbl(seq(0, 1, .1), ~repCluster1000(tau = .x, times = 1000))

#add these to the plot of results of 1c.

#plot results
as.data.frame(cbind(results, clus.results, seq(0, 1, .1))) %>%
  ggplot(aes(x = V3)) +
  geom_point(aes(y = results, color = "black")) +
  geom_line(aes(y = results, color = "black")) +
  geom_point(aes(y = clus.results, color = "blue")) +
  geom_line(aes(y = clus.results, color = "blue")) +
  theme_minimal() +
  labs(x = "Expected Value Yi for Treated", y = "Power") +
  ggtitle("Power for Various Treatment Effect Sizes") +
  scale_color_manual(values = c("black", "blue"), labels = c("standard","cluster"))



```




